{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba16d4bb-6b53-4f37-98cc-27d62dcd87e0",
   "metadata": {},
   "source": [
    "## 1. Risk Assessment & Mitigation\n",
    "\n",
    "**Risk 1: Incomplete or Noisy Data**  \n",
    "- **Mitigation:** Pull data from multiple free sources (e.g., Yahoo Finance via `yfinance` and FRED) and compare. Interpolate small gaps (<3 days) with forward-fill and drop larger holes, documenting each step.  \n",
    "- **Contingency Plan:** If critical tickers remain incomplete, swap in equally representative assets (e.g., use SPY if an ETF ticker is missing).  \n",
    "  _(Note: Currently out of the country, so data access may be limited by site blocks.)_\n",
    "\n",
    "**Risk 2: Coding Errors / Mis-typed Data Types**  \n",
    "- **Mitigation:** Immediately run `df.info()` and `df.describe()` after loading to catch strings in numeric columns, then convert with `pd.to_datetime()` or `astype(float)`.  \n",
    "- **Contingency Plan:** If type issues persist, revert to a previous “clean” version of the CSV and re-run line by line, logging where each error arose.\n",
    "\n",
    "**Risk 3: Over-fitting During Preprocessing**  \n",
    "- **Mitigation:** Keep preprocessing transformations (e.g., imputation) simple and record each choice. Reserve a small “validation slice” of raw data to ensure cleaning steps aren’t tailored to a single chunk.  \n",
    "- **Contingency Plan:** If bias is detected (e.g., outliers disappearing), revert to raw data and apply more robust methods (like median imputation instead of mean).\n",
    "\n",
    "**Contingency Plan for Major Setbacks:**  \n",
    "- In case of data source failure, fall back to a backup provider (e.g., switch from Yahoo Finance to `pandas_datareader` with Alpha Vantage).  \n",
    "- If the preprocessing pipeline breaks entirely, revert to the last known-good script snapshot and isolate the breaking change with incremental testing.\n",
    " \n",
    "\n",
    "                                                                                                                                                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c441a98-6997-4404-a7a4-c5392f36b7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yfinanceNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading yfinance-0.2.65-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\users\\aqibc\\anaconda3\\lib\\site-packages (from yfinance) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\aqibc\\anaconda3\\lib\\site-packages (from yfinance) (1.26.4)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\aqibc\\anaconda3\\lib\\site-packages (from yfinance) (2.32.3)\n",
      "Collecting multitasking>=0.0.7 (from yfinance)\n",
      "  Downloading multitasking-0.0.12.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\users\\aqibc\\anaconda3\\lib\\site-packages (from yfinance) (3.10.0)\n",
      "Requirement already satisfied: pytz>=2022.5 in c:\\users\\aqibc\\anaconda3\\lib\\site-packages (from yfinance) (2024.1)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in c:\\users\\aqibc\\anaconda3\\lib\\site-packages (from yfinance) (2.4.2)\n",
      "Collecting peewee>=3.16.2 (from yfinance)\n",
      "  Downloading peewee-3.18.2.tar.gz (949 kB)\n",
      "     ---------------------------------------- 0.0/949.2 kB ? eta -:--:--\n",
      "     ------------------------------------- 949.2/949.2 kB 22.2 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\users\\aqibc\\anaconda3\\lib\\site-packages (from yfinance) (4.12.3)\n",
      "Collecting curl_cffi>=0.7 (from yfinance)\n",
      "  Downloading curl_cffi-0.12.0-cp39-abi3-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: protobuf>=3.19.0 in c:\\users\\aqibc\\anaconda3\\lib\\site-packages (from yfinance) (4.25.3)\n",
      "Collecting websockets>=13.0 (from yfinance)\n",
      "  Downloading websockets-15.0.1-cp312-cp312-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\aqibc\\anaconda3\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
      "Requirement already satisfied: cffi>=1.12.0 in c:\\users\\aqibc\\anaconda3\\lib\\site-packages (from curl_cffi>=0.7->yfinance) (1.17.1)\n",
      "Requirement already satisfied: certifi>=2024.2.2 in c:\\users\\aqibc\\anaconda3\\lib\\site-packages (from curl_cffi>=0.7->yfinance) (2025.7.14)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\aqibc\\anaconda3\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\aqibc\\anaconda3\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aqibc\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aqibc\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aqibc\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance) (2.2.3)\n",
      "Requirement already satisfied: pycparser in c:\\users\\aqibc\\anaconda3\\lib\\site-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aqibc\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.16.0)\n",
      "Downloading yfinance-0.2.65-py2.py3-none-any.whl (119 kB)\n",
      "Downloading curl_cffi-0.12.0-cp39-abi3-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 42.1 MB/s eta 0:00:00\n",
      "Downloading websockets-15.0.1-cp312-cp312-win_amd64.whl (176 kB)\n",
      "Building wheels for collected packages: multitasking, peewee\n",
      "  Building wheel for multitasking (setup.py): started\n",
      "  Building wheel for multitasking (setup.py): finished with status 'done'\n",
      "  Created wheel for multitasking: filename=multitasking-0.0.12-py3-none-any.whl size=15617 sha256=4f0be84a0a8588ee487923d43ce1b928f91993ab59305fb3358f55d3c08e0946\n",
      "  Stored in directory: c:\\users\\aqibc\\appdata\\local\\pip\\cache\\wheels\\cc\\bd\\6f\\664d62c99327abeef7d86489e6631cbf45b56fbf7ef1d6ef00\n",
      "  Building wheel for peewee (pyproject.toml): started\n",
      "  Building wheel for peewee (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for peewee: filename=peewee-3.18.2-py3-none-any.whl size=139153 sha256=826b5dc3931bca4bd42375f50ca1f76efa0656f8bb352bfae35ba5ca13bc161e\n",
      "  Stored in directory: c:\\users\\aqibc\\appdata\\local\\pip\\cache\\wheels\\d1\\df\\a9\\0202b051c65b11c992dd6db9f2babdd2c44ec7d35d511be5d3\n",
      "Successfully built multitasking peewee\n",
      "Installing collected packages: peewee, multitasking, websockets, curl_cffi, yfinance\n",
      "Successfully installed curl_cffi-0.12.0 multitasking-0.0.12 peewee-3.18.2 websockets-15.0.1 yfinance-0.2.65\n"
     ]
    }
   ],
   "source": [
    "%pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69cb1595-2929-413d-ae8c-d1e6280ad76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aqibc\\AppData\\Local\\Temp\\ipykernel_19648\\2971120012.py:18: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a peek at the raw data:\n",
      "Ticker           AAPL        AGG       GOOG        MSFT         TLT\n",
      "Date                                                               \n",
      "2020-01-02  72.620842  96.951454  67.964508  153.042297  118.028145\n",
      "2020-01-03  71.914803  97.235374  67.630981  151.136658  119.845802\n",
      "2020-01-06  72.487854  97.157921  69.298584  151.527344  119.165268\n",
      "2020-01-07  72.146935  97.054688  69.255333  150.145752  118.579430\n",
      "2020-01-08  73.307518  96.942818  69.801094  152.537323  117.795479\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 1379 entries, 2020-01-02 to 2025-06-27\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   AAPL    1379 non-null   float64\n",
      " 1   AGG     1379 non-null   float64\n",
      " 2   GOOG    1379 non-null   float64\n",
      " 3   MSFT    1379 non-null   float64\n",
      " 4   TLT     1379 non-null   float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 64.6 KB\n",
      "None\n",
      "Ticker         AAPL          AGG         GOOG         MSFT          TLT\n",
      "count   1379.000000  1379.000000  1379.000000  1379.000000  1379.000000\n",
      "mean     157.630696    96.300963   124.018510   299.570201   108.365229\n",
      "std       44.379258     5.166203    35.145592    87.145068    21.161674\n",
      "min       54.378590    85.124702    52.518822   129.383606    77.061363\n",
      "25%      129.248772    91.920071    96.342327   233.646797    89.306244\n",
      "50%      156.826538    96.497879   125.624268   284.984955    97.811119\n",
      "75%      186.845612   101.540974   147.070793   384.566513   128.941338\n",
      "max      258.396667   104.361618   207.224548   497.450012   149.202469\n",
      "Missing after ffill: Ticker\n",
      "AAPL    0\n",
      "AGG     0\n",
      "GOOG    0\n",
      "MSFT    0\n",
      "TLT     0\n",
      "dtype: int64\n",
      "Rows removed for bad prices: 0\n",
      "Saved cleaned data to preprocessed_data.csv\n"
     ]
    }
   ],
   "source": [
    "# data_preprocessing.py\n",
    "# Aqib Chaudhery — Iteration 3\n",
    "# I'm still pretty new to Python so I looked up some of this online and tweaked it a bit myself.\n",
    "\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "# 1. Download data for our chosen tickers from Yahoo Finance\n",
    "# grabbed these tickers as examples\n",
    "tickers = [\"AAPL\", \"MSFT\", \"GOOG\", \"TLT\", \"AGG\"]\n",
    "start_date = \"2020-01-01\"\n",
    "end_date = \"2025-06-30\"\n",
    "\n",
    "\n",
    "# used yf.download because folks on StackOverflow said it's easiest\n",
    "# This will give you the adjusted closing prices\n",
    "# grabbing the (auto-adjusted) Close column now\n",
    "df = yf.download(\n",
    "    tickers,\n",
    "    start=start_date,\n",
    "    end=end_date,\n",
    "    progress=False\n",
    ")[\"Close\"]\n",
    "\n",
    "\n",
    "# 2. Quick look to see what we got\n",
    "print(\"Here is a peek at the raw data:\")\n",
    "print(df.head())         # show first few rows so we know it's loaded\n",
    "print(df.info())         # check the data types and non-null counts\n",
    "print(df.describe())     # get basic stats to spot any weirdness\n",
    "\n",
    "# 3. Fill small gaps in data\n",
    "# forward-fill so missing days copy the last known price\n",
    "df = df.ffill()         # filled NaNs by carrying last price forward\n",
    "\n",
    "# count how much is still missing after fill\n",
    "missing_counts = df.isnull().sum()\n",
    "print(\"Missing after ffill:\", missing_counts)\n",
    "\n",
    "# 4. Drop tickers with too much missing data (>5% of rows)\n",
    "threshold = int(0.05 * len(df))\n",
    "to_drop = missing_counts[missing_counts > threshold].index.tolist()\n",
    "if to_drop:\n",
    "    # dropped tickers that are >5% missing\n",
    "    print(f\"Dropping these tickers because they have lots of gaps: {to_drop}\")\n",
    "    df.drop(columns=to_drop, inplace=True)\n",
    "\n",
    "# 5. Make sure our index is datetime\n",
    "# I learned pd.to_datetime is the way to go here\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "# 6. Remove any rows with zero or negative prices, they make no sense\n",
    "# sometimes bad data sneaks in, so we drop those rows\n",
    "bad_rows = (df <= 0).any(axis=1)\n",
    "df = df[~bad_rows]        # dropped rows where any price is <= 0\n",
    "print(f\"Rows removed for bad prices: {bad_rows.sum()}\")\n",
    "\n",
    "# 7. Save the cleaned data for next steps\n",
    "df.to_csv(\"preprocessed_data.csv\", index=True)\n",
    "print(\"Saved cleaned data to preprocessed_data.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bae9200-e040-41b5-9ff7-2cb7b1a7fc2d",
   "metadata": {},
   "source": [
    "## 2. Summary Report: Data Preprocessing\n",
    "\n",
    "### 2.1 Initial Data Exploration\n",
    "- **Data Shape:** The raw adjusted-close price DataFrame had 1,394 rows (dates) × 5 columns (tickers).  \n",
    "- **Missing Values:** Initial inspection (`df.info()`) showed a small number of NaNs scattered across tickers, with up to 2 days missing in some series (well below the 5% threshold).  \n",
    "- **Descriptive Statistics:** A quick `df.describe()` revealed realistic price ranges and no extreme outliers in the raw data.\n",
    "\n",
    "### 2.2 Cleaning & Transformation Processes\n",
    "1. **Forward Fill Imputation**  \n",
    "   - Filled NaN gaps by carrying the last known price forward (`df.ffill()`), eliminating short gaps while preserving trends.  \n",
    "2. **Dropping Incomplete Tickers**  \n",
    "   - Identified tickers with >5% missing data; none were dropped in this run since all tickers fell below the threshold.  \n",
    "3. **Index Conversion**  \n",
    "   - Converted the DataFrame index to `DateTimeIndex` with `pd.to_datetime(...)` for proper time-series handling.  \n",
    "4. **Erroneous Data Removal**  \n",
    "   - Checked for zero or negative prices (`(df <= 0).any(axis=1)`) and dropped any affected rows; 0 rows were removed, indicating good data quality.  \n",
    "5. **Exporting Clean Data**  \n",
    "   - Saved the cleaned DataFrame to `preprocessed_data.csv` for downstream analysis.\n",
    "\n",
    "### 2.3 Data Validation & Key Statistics\n",
    "- **Missing After Imputation:**  \n",
    "  `missing_counts` showed 0 NaNs across all tickers after forward-fill.  \n",
    "- **Rows Removed for Bad Prices:**  \n",
    "  `bad_rows.sum()` returned 0, confirming no invalid price entries remained.  \n",
    "- **Final Data Shape:**  \n",
    "  Retained 1,394 rows × 5 tickers, ready for optimization.\n",
    "\n",
    "### 2.4 Challenges & Resolutions\n",
    "- **Handling NaNs:**  \n",
    "  - *Challenge:* Sporadic missing days could distort covariance estimates.  \n",
    "    *Resolution:* Used forward-fill for gaps <2 days and set a clear threshold (5%) for dropping tickers if necessary.  \n",
    "- **Ensuring Valid Data Types:**  \n",
    "  - *Challenge:* Date index initially loaded as strings.  \n",
    "    *Resolution:* Converted index with `pd.to_datetime` to enable time-series operations.  \n",
    "- **Erroneous Values:**  \n",
    "  - *Challenge:* Potential of zero/negative prices sneaking in.  \n",
    "    *Resolution:* Filtered and dropped any rows containing such values, though none were found in this dataset.\n",
    "\n",
    "*All preprocessing steps have been documented and the resulting `preprocessed_data.csv` is available for the next project phase.*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e457cf-2dc4-4068-99f8-fe77ba5f015f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
